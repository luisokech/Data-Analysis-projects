{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter-dash\n",
      "  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "Collecting ansi2html\n",
      "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: flask in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.1.2)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-dash) (6.9.1)\n",
      "Requirement already satisfied: ipython in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-dash) (8.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-dash) (2.27.1)\n",
      "Collecting dash\n",
      "  Downloading dash-2.10.2-py3-none-any.whl (10.3 MB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.5.5)\n",
      "Requirement already satisfied: retrying in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.3.3)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting dash-table==5.0.0\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (5.9.0)\n",
      "Requirement already satisfied: Werkzeug<2.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (2.0.3)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (8.0.4)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click>=5.1->flask->jupyter-dash) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask->jupyter-dash) (2.0.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash->jupyter-dash) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (6.1)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (0.1.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (5.1.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (61.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (4.9.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel->jupyter-dash) (302)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel->jupyter-dash) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (2.0.4)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->jupyter-dash) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->jupyter-dash) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->jupyter-dash) (2.0.5)\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, dash, ansi2html, jupyter-dash\n",
      "Successfully installed ansi2html-1.8.0 dash-2.10.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 jupyter-dash-0.4.2\n"
     ]
    }
   ],
   "source": [
    "pip install jupyter-dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95055c89375cd0210e670e88459dc49a7da6020d"
   },
   "source": [
    "<h1> Data Wrangling of Electoral Data</h1>\n",
    "<h2>Get our environment set up</h2>\n",
    "The first thing we'll need to do is load in the libraries we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59869c2685245e108d192ad4dc58c9c0d54dc3a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27f8c741738b2ae90171abd092ab5e8cbe19b8d4"
   },
   "source": [
    "<h2>Load Data</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55d471c1a1c4984c9378e746b1e837b9c303c0f4"
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "NA2 = pd.read_csv(\"../input/National Assembly 2002 - Updated.csv\", encoding = \"ISO-8859-1\")\n",
    "NA8 = pd.read_csv(\"../input/National Assembly 2008.csv\", encoding = \"ISO-8859-1\")\n",
    "NA13 = pd.read_csv(\"../input/National Assembly 2013.csv\", encoding = \"ISO-8859-1\")\n",
    "print(\"Data Dimensions are: \", NA2.shape)\n",
    "print(\"Data Dimensions are: \", NA8.shape)\n",
    "print(\"Data Dimensions are: \", NA13.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c67f78d3d25dbf7e4a9a48b40737f3e53ec7b91"
   },
   "source": [
    "<h2>Data Info</h2>\n",
    "\n",
    "Let's look into the info of provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "812173bde1b8ca847f4d927dc83d764fe06cc2cb"
   },
   "outputs": [],
   "source": [
    "print(\"NA 2002.csv\")\n",
    "NA2.info()\n",
    "print(\"\\nNA 2008.csv\")\n",
    "NA8.info()\n",
    "print(\"\\nNA 2013.csv\")\n",
    "NA13.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47b1efc6986b1fdfc30d5b598e4cf6e0dec57664"
   },
   "source": [
    "All three files have 11 columns. Row details are as follow:\n",
    "\n",
    "* NA 2002: 1,792\n",
    "* NA 2008: 2,315\n",
    "* NA 2013: 4,541\n",
    "\n",
    "NA 2002.cv file has fine data types. \n",
    "\n",
    "In NA 2008 & NA 2013 files:\n",
    "* 1st column name is missing and showing that it have int64 data type. \n",
    "* Turnout column has read as object.\n",
    "\n",
    "<h2>Data Wrangling </h2>\n",
    "Lets observe the 1st file in order to fix next two and merge them all into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0ad4fc2ba5ef8573374efe2d0284901cfb262e0"
   },
   "outputs": [],
   "source": [
    "print(NA2.head())\n",
    "print(NA8.head())\n",
    "print(NA13.head())\n",
    "print(NA8.columns, \"\\n>>\\n\", NA13.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b64e6155afef8a2b21f4b0b29235a5579ce5795"
   },
   "source": [
    "So the first column should be District. We will extract district names from Seat column.\n",
    "We will drop last column from NA13 because it contain no value..\n",
    "\n",
    "<b>Rename Column and Replace Values </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "229364fde1007f6a1d631f2a5fa58cd508670680"
   },
   "outputs": [],
   "source": [
    "\n",
    "NA8.rename(columns={'Unnamed: 0':'District'}, inplace=True)\n",
    "NA13.rename(columns={'Unnamed: 0':'District'}, inplace=True)\n",
    "print(\"NA 8: \", NA8.columns, \"\\nNA 13: \", NA13.columns)\n",
    "#NA13 = NA13.drop('Unnamed: 11', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8298f7a093015d4b7127564b09637945484b5b99"
   },
   "outputs": [],
   "source": [
    "NA8.District = NA8.Seat#.str.split(\"-\", expand=True)[0]\n",
    "#Add District column\n",
    "#NA8['District'] = NA8['Seat']\n",
    "NA8['District'] = NA8['District'].str.replace(\".\",\" \") # to deal with D.I. Khan\n",
    "# remove all those substring with () \n",
    "NA8['District'] = NA8['District'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "# remove numeric\n",
    "NA8['District']  = NA8['District'] .str.replace('[^a-zA-Z -]', '')\n",
    "#NA8['District'] = NA8['District'].str.replace(r\"Cum.*\",\"\")\n",
    "#NA8['District'] = NA8['District'].str.replace(r\"cum.*\",\"\")\n",
    "#na18['District'] = na18['District'].str.replace(r\"KUM.*\",\"\")\n",
    "# to convert Tribal Area III - Mohman into Tribal Area III\n",
    "NA8['District'] = NA8['District'].str.replace(r\"-.*\",\"\")\n",
    "NA8['District']  = NA8['District'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "NA8['District']  = NA8['District'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "NA8['District'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7010e17818bcb92213397480fb3c9903a8b20839"
   },
   "outputs": [],
   "source": [
    "NA13.District = NA13.Seat #.str.split(\"-\", expand=True)[0]\n",
    "#Add District column\n",
    "#NA13['District'] = NA13['Seat']\n",
    "NA13['District'] = NA8['District'].str.replace(\".\",\" \") # to deal with D.I. Khan\n",
    "# remove all those substring with () \n",
    "NA13['District'] = NA13['District'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "# remove numeric\n",
    "NA13['District']  = NA13['District'] .str.replace('[^a-zA-Z -]', '')\n",
    "NA13['District'] = NA13['District'].str.replace(r\"Cum.*\",\"\")\n",
    "#na18['District'] = na18['Distirct'].str.replace(r\"KUM.*\",\"\")\n",
    "# to convert Tribal Area III - Mohman into Tribal Area III\n",
    "NA13['District'] = NA13['District'].str.replace(r\"-.*\",\"\")\n",
    "NA13['District']  = NA13['District'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "NA13['District']  = NA13['District'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "NA13['District'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13d8e4eb980c9428ea10131fbfea165f2052e266"
   },
   "outputs": [],
   "source": [
    "NA13.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "597e75aef4ebcce75b518fbbd3671f45330e3d42"
   },
   "source": [
    "We are all set with first issue. Turnout column has % symbol in it which makes it object datatype. We will remove non-numeric characters and change datatype.\n",
    "\n",
    "<b>Change the datatype of Turnout column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa75d20cab697b22c024c2cf29fc416b4059b87d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NA8['Turnout'] = NA8['Turnout'].str.rstrip('%').str.rstrip(' ')\n",
    "NA13['Turnout'] = NA13['Turnout'].str.rstrip('%').str.rstrip(' ')\n",
    "NA8['Turnout'] = pd.to_numeric(NA8['Turnout'], errors='coerce')\n",
    "NA13['Turnout'] = pd.to_numeric(NA13['Turnout'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea9bb1081a0cd0da282a2130d47f16f899a6a84a"
   },
   "source": [
    "Now our dataset is aligned and ready to merge. But before merging, lets add another column  'Year'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b856886e8b3fc6c73039b958b67b8c0f4b8d787c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NA2['Year'] = \"2002\"\n",
    "NA8['Year'] = \"2008\"\n",
    "NA13['Year'] = \"2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43789824a12e91a73c09a0dc51d39fc308311483"
   },
   "outputs": [],
   "source": [
    "print(NA2.head(), \"\\n\", NA8.head(), \"\\n\", NA13.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9eaa6e44982048d15e28c17ed0622bdaaf7ec18b"
   },
   "source": [
    "<h2>NAN Values</h2>\n",
    "Lets check the status of NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70a0346667bc412a25dffda78c32eca2aff45725"
   },
   "outputs": [],
   "source": [
    "print(\"NA2\", NA2.isnull().any(), \"\\nNA8: \", NA8.isnull().any(), \"\\nNA13:\", NA13.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38605aec70afa458af28f9ff00b6cbb4791ebc8e"
   },
   "source": [
    "There is no null record.\n",
    "\n",
    "Final step before merging:\n",
    "\n",
    "Just to confirm that column names are similar in all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2edebec251d77a9531d9081d4555360a45db9c3"
   },
   "outputs": [],
   "source": [
    "print(\"\\n NA2\", NA2.columns, \"\\n NA8\", NA8.columns, \"\\n NA13\", NA13.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa8741bb25808e1162845e8d177ed1c3bf264504"
   },
   "outputs": [],
   "source": [
    "NA2.rename(columns={'Constituency_title':'ConstituencyTitle', 'Candidate_Name':'CandidateName', 'Total_Valid_Votes':'TotalValidVotes', 'Total_Rejected_Votes':'TotalRejectedVotes', 'Total_Votes':'TotalVotes', 'Total_Registered_Voters':'TotalRegisteredVoters', }, inplace=True)\n",
    "NA2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c912e3ac7f56391f972b17b520f44ad5d7dc6bb3",
    "collapsed": true
   },
   "source": [
    "<h2>Concatenate All 3 Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b2073dfd633f9899f208defe0c4e82535ea6fe5"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([NA2, NA8, NA13])\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9948a85db8c185419b44e2d2a52ebc4cf83545d7"
   },
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc92b7a7c3a20d9c6955bdbe5d4c76cd3dc21f0c"
   },
   "source": [
    "<h2>Some Preliminary Text Pre-processing</h2>\n",
    "Here, I'm interested in cleaning up all Text columns to make sure there's no data entry inconsistencies in it. We could go through and check each row by hand, of course, and hand-correct inconsistencies when we find them. There's a more efficient way to do this though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67cab52c107ddfcbc8409f7d9ecbd9c19f1411a6"
   },
   "outputs": [],
   "source": [
    "# get all the unique values in the 'District' column\n",
    "#df['District'] = df['District'].astype(str)\n",
    "dist = df['District'].unique()\n",
    "#dist.sort()\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bcb35ba0138919a336bc96e13c208aaf9b4f43d9"
   },
   "source": [
    "Just looking at this, We can see some problems due to inconsistent data entry: 'PESHAWAR' and Peshawar ', for example, or 'Charsadda' and 'Charsdda'.\n",
    "\n",
    "The first thing we are going to do is make everything lower case (we can change it back at the end if need) and remove any white spaces at the beginning and end of cells. Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "815fc35cf0a97084b03dcf7c962a67e0eed868fa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "df['District'] = df['District'].str.lower()\n",
    "# remove trailing white spaces\n",
    "df['District'] = df['District'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c630f0146bad5d255ec46b7ac08d2c4d8a8fb8fa"
   },
   "source": [
    "<h2>Use fuzzy matching to correct inconsistent data entry</h2>\n",
    "Alright, let's take another look at the district column and see if there's any more data cleaning we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99a482c70e661ddc45454e0e688b12e447182fa5"
   },
   "outputs": [],
   "source": [
    "dist = df['District'].unique()\n",
    "#dist.sort()\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58aa1b97218fb18536009ef4cf9449c2dfbc376e"
   },
   "source": [
    "It does look like there are some remaining inconsistencies: 'charsadda' and 'charsdda' should probably be the same. \n",
    "\n",
    "We are going to use the fuzzywuzzy package to help identify which string are closest to each other. \n",
    "> <b>Fuzzy matching:</b> The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n",
    "\n",
    "Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of districts that have the closest distance to \"charsadda\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fbbaf4606b11e3574784dd75dee5c74a7212bf3"
   },
   "outputs": [],
   "source": [
    "# get the top 10 closest matches to \"charsadda\"\n",
    "matches = fuzzywuzzy.process.extract(\"charsadda\", dist, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "815e022247d27710f9761653dc3bd7796be66690"
   },
   "source": [
    "We can see that two of the items in the districts are very close to \"charsadda\": 'charsadda; and 'charsdda'.\n",
    "\n",
    "Let's replace all rows in our District column that have a ratio of > 90 with \"charsadda\".\n",
    "\n",
    "For the reusability,  I'm going to write a function to fix all these challenges ASAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8327d743cc7e537b130ef1c34584672d9deccf91",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to replace rows in the provided column of the provided dataframe\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2885eb318d277808b06a7578d82c6007472207da"
   },
   "source": [
    "To test the funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "573f78b4cfd2d56220a7c0796116f0d2313e928b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the function we just wrote to replace close matches to \"charsadda\" \n",
    "replace_matches_in_column(df=df, column='District', string_to_match=\"charsadda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0da09117f9c35d19c0f353f778908f186370871"
   },
   "outputs": [],
   "source": [
    "dist = df['District'].unique()\n",
    "#dist.sort()\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fded207417e99111d1f3e0a1149b3a7131c5c0ea"
   },
   "source": [
    "Lets fix few more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "024db41d4f95601b4dfd40041c5a0f0f9987bb68",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_matches_in_column(df=df, column='District', string_to_match=\"nowshera\")\n",
    "replace_matches_in_column(df=df, column='District', string_to_match=\"rawalpindi\")\n",
    "replace_matches_in_column(df=df, column='District', string_to_match=\"sheikhupura\")\n",
    "replace_matches_in_column(df=df, column='District', string_to_match=\"shikarpur\")\n",
    "replace_matches_in_column(df=df, column='District', string_to_match=\"nankana sahib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9fee111be182e7217f8261fb1cb65ff7a1320768"
   },
   "source": [
    "<h3>Lets Clean data around Party & Candidates Name </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65c0cb302dd32c8d8fd3a3d0026778585ac77cd6"
   },
   "outputs": [],
   "source": [
    "del dist\n",
    "\n",
    "pty = df['Party'].unique()\n",
    "pty.sort()\n",
    "pty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d932deaa579655ab33ef090245e9877128643e57",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Party'] = df['Party'].replace(['MUTTHIDA\\xa0MAJLIS-E-AMAL\\xa0PAKISTAN'], 'Muttahidda Majlis-e-Amal Pakistan')\n",
    "df['Party'] = df['Party'].replace(['Pakistan Muslim League'], 'Pakistan Muslim League (QA)')\n",
    "#converting text to lower case & removing white spaces\n",
    "df['Party'] = df['Party'].str.lower()\n",
    "df['Party'] = df['Party'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b35d39d4928b46d840015f8bcd3f110092bf86f",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# As I coded this earlier, I wouldn't change it due to lower case letters. \n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Balochistan National Movement\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Independent\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Istiqlal Party\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Jamote Qaumi Movement\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Labour Party Pakistan\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Mohib-e-Wattan Nowjawan Inqilabion Ki Anjuman (MNAKA)\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Muttahida Qaumi Movement\") # Muttahida Qaumi Movement Pakistan\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Muttahidda Majlis-e-Amal\") # Muttahidda Majlis-e-Amal Pakistan\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"National Peoples Party\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Nizam-e-Mustafa Party\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pak Muslim Alliance\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Awami Party\")\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Democratic Party\")\n",
    "# After analyzing each of the below strings.\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Muslim League (QA)\", min_ratio =97)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Muslim League (N)\", min_ratio =97)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Muslim League (J)\", min_ratio =97)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Muslim League (F)\", min_ratio =97)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Peoples Party Parliamentarians\", min_ratio =97)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Peoples Party(Shaheed Bhutto)\", min_ratio =95)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Peoples Party(Sherpao)\", min_ratio =97)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Pakistan Tehreek-e-Insaf\", min_ratio =95)\n",
    "replace_matches_in_column(df=df, column='Party', string_to_match=\"Saraiki Sooba Movement Pakistan\", min_ratio =95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cee89cb9234f1193c34039a4d94bd60bfd5c390d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fuzzywuzzy.process.extract(\"Pakistan Muslim League (QA)\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >97\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Muslim League (N)\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >97\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Muslim League (J)\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >97\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Muslim League (F)\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >97\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Peoples Party Parliamentarians\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >97\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Peoples Party(Shaheed Bhutto)\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >95\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Peoples Party(Sherpao)\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >97\n",
    "#fuzzywuzzy.process.extract(\"Pakistan Tehreek-e-Insaf\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >95\n",
    "#fuzzywuzzy.process.extract(\"Saraiki Sooba Movement Pakistan\", pty, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8311a3342e048d0df4beff59a01fa3342dc8d3a5"
   },
   "outputs": [],
   "source": [
    "df['Party'] = df['Party'].str.lower()\n",
    "# few fixes taken from https://www.kaggle.com/usman786/exploratory-data-analysis-for-interesting-insights/notebook\n",
    "df['Party'].replace(['muttahida qaumi movement pakistan'], 'muttahida qaumi movement', inplace = True)\n",
    "df['Party'].replace(['indeindependentdente','independent (retired)','indepndent'], 'independent',inplace = True)\n",
    "df['Party'].replace(['indeindependentdente','independent (retired)','indepndent'], 'independent',inplace = True)\n",
    "df['Party'].replace(['muttahidda majlis-e-amal pakistan','mutthida\\xa0majlis-e-amal\\xa0pakistan'\n",
    "                     ,'mutthidaï¿½majlis-e-amalï¿½pakistan'] \n",
    "                     ,'muttahidda majlis-e-amal' ,inplace = True)\n",
    "df['Party'].replace(['nazim-e-mistafa'], 'nizam-e-mustafa party' ,inplace = True)\n",
    "df['Party'].replace(['pakistan muslim league (qa)'], 'pakistan muslim league (q)' ,inplace = True)\n",
    "df['Party'].replace(['pakistan muslim league council'], 'pakistan muslim league (c)' ,inplace = True)\n",
    "df['Party'].replace(['pakistan muslim league \\x93h\\x94 haqiqi'], 'pakistan muslim league haqiqi' ,inplace = True)\n",
    "df['Party'].replace(['pakistan muslim league(z)'], 'pakistan muslim league (z)' ,inplace = True)\n",
    "df['Party'].replace(['pakistan peoples party(shaheed bhutto)'], 'pakistan peoples party (shaheed bhutto)' ,inplace = True)\n",
    "df['Party'].replace(['pakistan peoples party parliamentarians'], 'pakistan peoples party parliamentarians' ,inplace = True)\n",
    "df['Party'].replace(['pakistan sariaki party'], 'Pakistan Siraiki Party (T)' ,inplace = True)\n",
    "df['Party'].replace(['pasban'], 'pasban pakistan' ,inplace = True)\n",
    "df['Party'].replace(['qaumi watan party (sherpao)'], 'qaumi watan party' ,inplace = True)\n",
    "df['Party'].replace(['tehreek-e-suba hazara'], 'tehreek-e-suba hazara pakistan' ,inplace = True)\n",
    "#...\n",
    "df['Party'].replace(['pashtoonkhwa milli awami party'], 'pakhtoonkhwa milli Awami party' ,inplace = True)\n",
    "df['Party'].replace(['pakistan amn party'], 'pakistan aman party' ,inplace = True)\n",
    "df['Party'].replace(['pakistan awami inqelabi'], 'Pakistan Awami Inqelabi League' ,inplace = True)\n",
    "df['Party'].replace(['pakistan freedom party'], 'pakistan freedom movement' ,inplace = True)\n",
    "df['Party'].replace(['pakistan insani haqook party (pakistan human rights party)'], 'pakistan human rights party' ,inplace = True)\n",
    "df['Party'].replace(['awami justice party'], 'awami justice party pakistan' ,inplace = True)\n",
    "df['Party'].replace(['indeindependentdent'], 'independent' ,inplace = True)\n",
    "df['Party'].replace(['jamiat ulama-e-pakistan  (noorani)'], 'jamiat ulama-e-pakistan (noorani)' ,inplace = True)\n",
    "df['Party'].replace(['jumiat ulma-e-islam(nazryati)'], 'jamiat ulma-e-islam nazryati pakistan' ,inplace = True)\n",
    "df['Party'].replace(['majlis-e-wahdat-e-muslimeen pakistan'], 'Majlis Wahdat-e-Muslimeen Pakistan' ,inplace = True)\n",
    "df['Party'].replace(['markazi jamat-al-hadais'], 'Markazi Jamiat Ahl-e-Hadith' ,inplace = True)\n",
    "df['Party'].replace(['mohib-e-wattan nowjawan inqilabion ki anjuman (mnaka)'], 'Muhib-e-Watan Noujawan Anqlabion Ki Anjuman (MNAKA)' ,inplace = True)\n",
    "\n",
    "pty = df['Party'].unique()\n",
    "pty.sort()\n",
    "pty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c161ce955f3e0e7a016241dea2d6f20ed36ead2"
   },
   "outputs": [],
   "source": [
    "#del pty\n",
    "#convert textual content to lower case & remove trailing white spaces\n",
    "df['CandidateName'] = df['CandidateName'].str.lower()\n",
    "df['CandidateName'] = df['CandidateName'].str.strip()\n",
    "df['CandidateName'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58f8850e6414b488ae234542512b5159861b31db"
   },
   "source": [
    "We will remove Mr Initial from the begining of names, But we will keep Dr Initial because it is worth gaining title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36927a5448a83ca368b186afb1c2284e2f3ddc3e"
   },
   "outputs": [],
   "source": [
    "# remove mr at the beginning of names.\n",
    "df['CandidateName'] = df.loc[:, 'CandidateName'].replace(regex=True, to_replace=\"mr \", value=\"\")\n",
    "df['CandidateName'] = df.loc[:, 'CandidateName'].replace(regex=True, to_replace=\"mrs \", value=\"\")\n",
    "df['CandidateName'] = df.loc[:, 'CandidateName'].replace(regex=True, to_replace=\"miss \", value=\"\")\n",
    "#df['CandidateName'] = df.loc[:, 'CandidateName'].replace(regex=True, to_replace=\"mis \", value=\"\")\n",
    "df['CandidateName'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a5a4f8ec51bc24e0717acb03905b4cc057e7f08"
   },
   "outputs": [],
   "source": [
    "cn = df['CandidateName'].unique()\n",
    "cn.sort()\n",
    "print(\"cn size: \", cn.shape, \"\\nValues: \", cn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "902dbc16a9110f95223eb8148cfaed1fd0bd8bfc"
   },
   "outputs": [],
   "source": [
    "df['CandidateName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa70b61cfb3d2c4b52210d13f946515a6b46c19c"
   },
   "source": [
    "Lets observe few to set the threshold for fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f30ead8500fde5bb806dd916e43464b0d860014"
   },
   "outputs": [],
   "source": [
    "fuzzywuzzy.process.extract(\"zumurad khan\", cn, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >90\n",
    "fuzzywuzzy.process.extract(\"zobaida jalal\", cn, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >79\n",
    "#fuzzywuzzy.process.extract(\"barkat ali\", cn, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >90\n",
    "#fuzzywuzzy.process.extract(\"sher muhammad baloch\", cn, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >90\n",
    "#fuzzywuzzy.process.extract(\"gulab baloch\", cn, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >90\n",
    "#fuzzywuzzy.process.extract(\"babu gulab\", cn, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio) # acceptance value >90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d62cb9fa6a1d8dc84a4b715cc6eeb37fcae9b52"
   },
   "outputs": [],
   "source": [
    "replace_matches_in_column(df=df, column='CandidateName', string_to_match=\"zumurad khan\", min_ratio=92)\n",
    "replace_matches_in_column(df=df, column='CandidateName', string_to_match=\"zobaida jalal\", min_ratio=80)\n",
    "replace_matches_in_column(df=df, column='CandidateName', string_to_match=\"barkat ali\", min_ratio=90)\n",
    "replace_matches_in_column(df=df, column='CandidateName', string_to_match=\"muhammad yasin baloch\", min_ratio=90)\n",
    "\n",
    "for candi in df['CandidateName'].unique(): # 7000\n",
    "    replace_matches_in_column(df=df, column='CandidateName', string_to_match=candi, min_ratio=90)\n",
    "\n",
    "# let us know the loop is completed\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80f3aa11745f9bbe333e423193287c125178c8be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del NA2, NA8, NA13\n",
    "df.to_csv('NA2002-18.csv', index=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "49d3f82c0847e28b4e1590a5d49b124fbc7c1d34"
   },
   "source": [
    "<h2>Candidate List & Parties of 2018 Election</h2>\n",
    "Lets se if these 2 files need some cleaning as well. We will merge both files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64b5c628e93f343cdb75b42bfedd97fc533082fc"
   },
   "outputs": [],
   "source": [
    "cc = pd.read_csv(\"../input/National Assembly Candidates List - 2018 Updated.csv\", encoding = \"ISO-8859-1\")\n",
    "na18 = pd.read_csv(\"../input/2013-2018 Seat Changes in NA.csv\", encoding = \"ISO-8859-1\") \n",
    "pp = pd.read_csv(\"../input/Political Parties in 2018 Elections - Updated.csv\", encoding = \"ISO-8859-1\")\n",
    "print(cc.shape, na18.shape, pp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc7298b783e558777022838288054514b5757ec0"
   },
   "outputs": [],
   "source": [
    "print(cc.columns, na18.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8131a28623cafdfc3c6b836e6606cb378260b81d"
   },
   "source": [
    "Adding \"NA-\" string in NA# column to merge it with na18 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59a0fc9149a7fc4231743b069d557b39e35fb3d4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc['NA#'] = 'NA-' + cc['NA#'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8556718e260d978f2ab1607e8eb7a346b38570ab"
   },
   "outputs": [],
   "source": [
    "print(cc['NA#'].unique().shape) # 272\n",
    "print(na18['2018 Seat Number'].unique().shape) # 273\n",
    "na18.rename(columns={'2018 Seat Number':'NA#'}, inplace=True)\n",
    "na18.rename(columns={'Seat Name':'Seat'}, inplace=True)\n",
    "na18[na18['NA#'] == \"Old Constituency Changed Considerably\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17dfcab3231a059955426a1342adb978d4724b03"
   },
   "outputs": [],
   "source": [
    "na18 = na18[na18['NA#'] != \"Old Constituency Changed Considerably\"]\n",
    "na18['NA#'] = na18.loc[:, 'NA#'].replace(regex=True, to_replace=\"NA-\", value=\"\")\n",
    "na18['NA#'] = pd.to_numeric(na18['NA#'])\n",
    "na18['NA#'] = na18['NA#'].astype(np.int64)\n",
    "na18['NA#'] = 'NA-' + na18['NA#'].astype(str)\n",
    "#na18['NA#'] = na18.loc[:, 'NA#'].replace(regex=True, to_replace=\".0\", value=\"\")\n",
    "na18['NA#'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b999266250400db5c777988f8d5bf5c7155965d",
    "collapsed": true
   },
   "source": [
    "Lets add District column and do its cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d121d617b8a7d6b96f9d0e65648f26c2db9cb91"
   },
   "outputs": [],
   "source": [
    "#Add District column & its cleani\n",
    "na18['Distirct'] = na18['Seat']\n",
    "# remove all those substring with () \n",
    "na18['Distirct'] = na18['Distirct'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "# remove numeric\n",
    "na18['Distirct']  = na18['Distirct'].str.replace('[^a-zA-Z -]', '')\n",
    "na18['Distirct'] = na18['Distirct'].str.replace(r\"Cum.*\",\"\")\n",
    "#na18['Distirct'] = na18['Distirct'].str.replace(r\"KUM.*\",\"\")\n",
    "# to convert Tribal Area III - Mohman into Tribal Area III\n",
    "na18['Distirct'] = na18['Distirct'].str.replace(r\"-.*\",\"\")\n",
    "na18['Distirct']  = na18['Distirct'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "na18['Distirct']  = na18['Distirct'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "na18['Distirct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c4b6f9353d0c411fbcddac2212ae763e2a51c9d"
   },
   "outputs": [],
   "source": [
    "cc = cc.join(na18.set_index('NA#'), on='NA#')\n",
    "cc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6aa2f4d58f8f901a7631d74c1ba442a2ce2c2f34"
   },
   "outputs": [],
   "source": [
    "print(pp.shape)\n",
    "pp['Name of Political Party'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b66aa300ace4bbea7e9ee53436de5fd055bfa750",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.rename(columns={'Acronym':'PartyAcro'}, inplace=True)\n",
    "cc.rename(columns={'Party':'PartyAcro'}, inplace=True)\n",
    "pp.rename(columns={'Name of Political Party':'Party'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa5605f8d1ac59ee5811cc3a0b2f437316474f1a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean Candidate file\n",
    "pp['Party'].replace(['pakistan reh-e- haq party'], 'Pakistan Rah-e- Haq Party' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Muslim League SHER-E-BANGAL A.K. Fazal-Ul-Haque'], 'pakistan muslim league (sher-e-bangal)' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Muslim League (Zia-ul-Haq Shaheed)'], 'pakistan muslim league (z)' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Muslim League (Junejo)'], 'pakistan muslim league (j)' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Muslim League (Functional)'], 'pakistan muslim league (f)' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Muslim League (Council)'], 'pakistan muslim league (c)' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Muslim League-Nawaz'], 'pakistan muslim league (n)' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Justice & Democratic Party'], 'Pakistan Justice and Democratic Party' ,inplace = True)\n",
    "pp['Party'].replace(['Pakistan Kissan Ittehad (Ch. Anwar)'], 'Pakistan Kissan Ittehad' ,inplace = True)\n",
    "pp['Party'].replace(['Jamiat Ulma-e-Islam Nazryati Pakistan'], 'Jamiat Ulma-e-Islam Nazaryati Pakistan' ,inplace = True)\n",
    "pp['Party'].replace(['Jamiat Ulma-e-Islam Nazryati Pakistan'], 'Jamiat Ulma-e-Islam Nazaryati Pakistan' ,inplace = True)\n",
    "pp['Party'].replace(['Jamiat Ulama-e-Islam(F)'], 'Jamiat Ulama-e-Islam (F)' ,inplace = True)\n",
    "pp['Party'].replace(['Jamiat Ulama-e-Islam(S)'], 'Jamiat Ulama-e-Islam (S)' ,inplace = True)\n",
    "pp['Party'].replace(['Mohajir Qaumi Movement (Pakistan)'], 'Mohajir Qaumi Movement pakistan' ,inplace = True)\n",
    "pp['Party'].replace(['Mutahida Majlis-e-Amal'], 'Muttahida Majlis-e-Amal' ,inplace = True)\n",
    "pp['Party'].replace(['Muttahidda Qaumi Movement Pakistan'], 'Muttahida Qaumi Movement Pakistan' ,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcf081d4a7bfebffe0074b280a363a045ed82fa9"
   },
   "outputs": [],
   "source": [
    "# Remove duplicaties\n",
    "pp.drop_duplicates(subset=['PartyAcro'], keep=\"first\", inplace=True)\n",
    "pp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be7f230ba0d73ef4f87c2a14363ac0cc4e16465d"
   },
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b54805a0fdf705e390112789f9c9f3830b6722d"
   },
   "outputs": [],
   "source": [
    "cc[cc['PartyAcro']=='PTI'].head()\n",
    "#pp[pp['PartyAcro']=='PTEI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df8894f5492a07693b5af6106d3bac84fabfe73d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del cnd\n",
    "cnd = cc.join(pp.set_index('PartyAcro'), on='PartyAcro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54e2e13d47e763edc301d7b30a452a310e4e7125"
   },
   "outputs": [],
   "source": [
    "cnd.info()\n",
    "cnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5867bd7a56b07efc0aa184ac9f98a0f866236f52"
   },
   "outputs": [],
   "source": [
    "cnd[cnd['PartyAcro']==\"PTI\"].head()\n",
    "#remove non-aplhabetic characters from Name\n",
    "cnd['Name'] = cnd['Name'].str.replace('[^a-zA-Z ]', '')\n",
    "cnd['Name'] = cnd['Name'].str.lower()\n",
    "cnd['Name'] = cnd['Name'].str.strip()\n",
    "\n",
    "cnd['Party'] = cnd['Party'].str.lower()\n",
    "cnd['Party'] = cnd['Party'].str.strip()\n",
    "\n",
    "cnd[cnd['PartyAcro']==\"PTI\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fdb2ba0adee39b7b3e9a7fae3d5fc78c680b001"
   },
   "source": [
    "Merging .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c87c33a2dbeba70c4fdca506ba74b683dcf11845"
   },
   "outputs": [],
   "source": [
    "print(df.columns, cnd.columns)\n",
    "df.info()\n",
    "cnd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c36d02132a91a0c1fb8b74374bd71ffe4186eac1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnd.rename(columns={'NA#':'ConstituencyTitle'}, inplace=True)\n",
    "cnd.rename(columns={'Name of Political Party':'Party'}, inplace=True)\n",
    "cnd.rename(columns={'Name':'CandidateName'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "901804d91350723531234b9e915891eb41203861",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnd.to_csv('Canditates2018.csv', index=None) \n",
    "pp.to_csv('Parties_cleand.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ce295be10792bb460a2183067157215d1eea33c"
   },
   "source": [
    "<h3><u>Note: Both files can not is mergered easily as NA mapping is changed for current year.  </u></h3>\n",
    "I will use both files in EDA and Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab9cd3068a97a8e9768c6656d5418bccd3807965",
    "collapsed": true
   },
   "source": [
    "That's all from me. I tried to clean maximum of the data inconsistency issues. So, I am saving this file for the audience for the seek a reusability. You can fork kernel and continue from here.\n",
    "\n",
    "We are all set to move towards <b>Exploratory Data Analysis </b>. \n",
    "\n",
    "Do share your comments and if you find it helpful, <b>please upvote! </b>\n",
    "<h2> Happy Exploratory Analsysis :-) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f51256f580890b9ed0b49ecf39062c9b1b101b5"
   },
   "source": [
    "<h2> Data Cleaning of NA 2018 Election Results <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8efad6f264f12071815e3ebaac1bb08e91c51f4c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reading 2018 Results Data\n",
    "NA18 = pd.read_csv(\"../input/NA-Results2018 Ver 2.csv\", encoding = \"ISO-8859-1\")\n",
    "print(\"Data Dimensions of NA18 are: \", NA18.shape)\n",
    "\n",
    "print(\"\\nNA 2018.csv\")\n",
    "NA18.info()\n",
    "\n",
    "NA18 = NA18.drop('Unnamed: 0', axis=1)\n",
    "NA18.rename(columns={'district':'District'}, inplace=True)\n",
    "\n",
    "NA18.District = NA18.Seat\n",
    "NA18['District'] = NA18['District'].str.replace(\".\",\" \") # to deal with D.I. Khan\n",
    "NA18['District'] = NA18['District'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "NA18['District']  = NA18['District'] .str.replace('[^a-zA-Z -]', '')\n",
    "NA18['District'] = NA18['District'].str.replace(r\"-.*\",\"\")\n",
    "NA18['District']  = NA18['District'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "NA18['District']  = NA18['District'] .str.replace(r\" (XX|IX|X?I{0,3})(IX|IV|V?I{0,3})$\", '')\n",
    "NA18['District'].unique()\n",
    "\n",
    "NA18['Turnout'] = NA18['Turnout'].str.rstrip('%').str.rstrip(' ')\n",
    "NA18['Turnout'] = pd.to_numeric(NA18['Turnout'], errors='coerce')\n",
    "NA18.rename(columns={'Constituency_Title':'ConstituencyTitle', 'Candidate_Name':'CandidateName', 'Total_Valid_Votes':'TotalValidVotes', 'Total_Rejected_Votes':'TotalRejectedVotes', 'Total_Votes':'TotalVotes', 'Total_Registered_Voters':'TotalRegisteredVoters', 'Part':'Party' }, inplace=True)\n",
    "NA18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db989e24539d99823de182a6454f80a98386b3de",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "NA18['District'] = NA18['District'].str.lower()\n",
    "# remove trailing white spaces\n",
    "NA18['District'] = NA18['District'].str.strip()\n",
    "\n",
    "# convert to lower case\n",
    "NA18['CandidateName'] = NA18['CandidateName'].str.lower()\n",
    "# remove trailing white spaces\n",
    "NA18['CandidateName'] = NA18['CandidateName'].str.strip()\n",
    "\n",
    "# convert to lower case\n",
    "NA18['Party'] = NA18['Party'].str.lower()\n",
    "# remove trailing white spaces\n",
    "NA18['Party'] = NA18['Party'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3eaa2045fd05aeadbf858568c0cc68a63741eef6"
   },
   "outputs": [],
   "source": [
    "NA18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a6d294118f68d2f446bddd2d84f0e6855b41260",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NA18.to_csv('NA2018_Clean.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
